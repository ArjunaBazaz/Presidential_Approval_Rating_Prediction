{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3cUqca0T6sA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Start Date    End Date  Approving  Disapproving  Unsure/NoData  Candidate\n",
            "0    2025-01-02   1/15/2025         40            54              6      biden\n",
            "1    2024-12-02  12/18/2024         39            56              5      biden\n",
            "2    2024-11-06  11/20/2024         37            58              6      biden\n",
            "3    2024-10-14  10/27/2024         41            39              3      biden\n",
            "4    2024-10-01  10/12/2024         39            56              5      biden\n",
            "...         ...         ...        ...           ...            ...        ...\n",
            "1902 1941-08-26  08/26/1941         67            24              7  roosevelt\n",
            "1903 1941-08-19  08/19/1941         65            26              7  roosevelt\n",
            "1904 1941-08-05  08/05/1941         68            23              7  roosevelt\n",
            "1905 1941-07-29  07/29/1941         65            25              8  roosevelt\n",
            "1906 1941-07-22  07/22/1941         69            24              6  roosevelt\n",
            "\n",
            "[1907 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load approval ratings\n",
        "file_paths = [\n",
        "    '../DATA/approval_rating_biden_1_updated.csv',\n",
        "    '../DATA/approval_rating_trump_1_updated.csv',\n",
        "    '../DATA/approval_rating_obama_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_bushjr_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_clinton_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_bushsr_1_updated.csv',\n",
        "    '../DATA/approval_rating_reagan_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_carter_1_updated.csv',\n",
        "    '../DATA/approval_rating_ford_1_updated.csv',\n",
        "    '../DATA/approval_rating_nixon_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_johnson_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_kennedy_1_updated.csv',\n",
        "    '../DATA/approval_rating_eisenhower_1_2_updated.csv',\n",
        "    '../DATA/approval_rating_truman_1_updated.csv',\n",
        "    '../DATA/approval_rating_roosevelt_3_4_updated.csv',\n",
        "]\n",
        "\n",
        "# read/concat\n",
        "approval = pd.concat([pd.read_csv(f, sep='\\t') for f in file_paths], ignore_index=True)\n",
        "approval.columns = ['Start Date', 'End Date', 'Approving', 'Disapproving', 'Unsure/NoData', 'Candidate']\n",
        "approval['Start Date'] = pd.to_datetime(approval['Start Date'], format='%m/%d/%Y')\n",
        "\n",
        "approval.to_csv(\"../DATA/approval_rating.csv\", index=False)\n",
        "print(approval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXZLJYOPUNMX"
      },
      "outputs": [],
      "source": [
        "# load econ data\n",
        "gdp = pd.read_csv('../DATA/real_GDP_per_capita.csv', index_col=False)\n",
        "gdp_change = pd.read_csv('../DATA/real_GDP_per_capita_daily_change.csv', index_col=False)\n",
        "income = pd.read_csv('../DATA/median_household_income.csv', index_col=False)\n",
        "income_change = pd.read_csv('../DATA/median_household_income_daily_change.csv', index_col=False)\n",
        "sp500 = pd.read_csv('../DATA/sp500_historical_data.csv', index_col=False)\n",
        "sp500_change = pd.read_csv('../DATA/sp500_daily_change.csv', index_col=False)\n",
        "unemployment = pd.read_csv('../DATA/unemployment_rate.csv', index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHuvUSkYUQXe"
      },
      "outputs": [],
      "source": [
        "# rename columns for clean names\n",
        "gdp.rename(columns={'A939RX0Q048SBEA': 'GDP', 'observation_date': 'observation_date'}, inplace=True)\n",
        "gdp_change.rename(columns={'A939RX0Q048SBEA': 'GDP_Change', 'observation_date': 'observation_date'}, inplace=True)\n",
        "\n",
        "income.rename(columns={'MEHOINUSA672N': 'Income', 'observation_date': 'observation_date'}, inplace=True)\n",
        "income_change.rename(columns={'MEHOINUSA672N': 'Income', 'Change': 'Income_Change', 'observation_date': 'observation_date'}, inplace=True)\n",
        "\n",
        "unemployment.rename(columns={'UNRATE': 'Unemployment', 'observation_date': 'observation_date'}, inplace=True)\n",
        "sp500.rename(columns={'Close': 'SP500_Close'}, inplace=True)\n",
        "sp500_change.rename(columns={'Close_Change': 'SP500_Close_Change'}, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "YKt3KJC4US0g",
        "outputId": "26cdb83c-9bdd-4852-c5af-483ec3ce3f3b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-181ca159bc26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make dates datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgdp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgdp_change\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdp_change\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mincome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincome_change\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincome_change\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observation_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# make dates datetime format\n",
        "gdp['observation_date'] = pd.to_datetime(gdp['observation_date'])\n",
        "gdp_change['observation_date'] = pd.to_datetime(gdp_change['observation_date'])\n",
        "income['observation_date'] = pd.to_datetime(income['observation_date'])\n",
        "income_change['observation_date'] = pd.to_datetime(income_change['observation_date'])\n",
        "sp500['Date'] = pd.to_datetime(sp500['Date'], utc=True).dt.tz_localize(None)\n",
        "sp500_change['Date'] = pd.to_datetime(sp500_change['Date'], utc=True).dt.tz_localize(None)\n",
        "unemployment['observation_date'] = pd.to_datetime(unemployment['observation_date'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2uTErJeUWNK"
      },
      "outputs": [],
      "source": [
        "# sort values for merge_asof()\n",
        "approval = approval.sort_values(by='Start Date')\n",
        "gdp = gdp.sort_values(by='observation_date')\n",
        "gdp_change = gdp_change.sort_values(by='observation_date')\n",
        "income = income.sort_values(by='observation_date')\n",
        "income_change = income_change.sort_values(by='observation_date')\n",
        "unemployment = unemployment.sort_values(by='observation_date')\n",
        "sp500 = sp500.sort_values(by='Date')\n",
        "sp500_change = sp500_change.sort_values(by='Date')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IOnOpW9UYV5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# merge\n",
        "df = pd.merge_asof(approval, gdp, left_on='Start Date', right_on='observation_date', direction='backward')\n",
        "df.drop(columns=['observation_date'], inplace=True)\n",
        "\n",
        "df = pd.merge_asof(df, gdp_change, left_on='Start Date', right_on='observation_date', direction='backward')\n",
        "df.drop(columns=['observation_date'], inplace=True)\n",
        "\n",
        "df = pd.merge_asof(df, income, left_on='Start Date', right_on='observation_date', direction='backward')\n",
        "df.drop(columns=['observation_date'], inplace=True)\n",
        "\n",
        "# Drop  Date After Merge\n",
        "df = pd.merge_asof(df, income_change, left_on='Start Date', right_on='observation_date', direction='backward')\n",
        "df.drop(columns=['observation_date'], inplace=True)  # ✅ THIS IS THE FIX\n",
        "\n",
        "df = pd.merge_asof(df, unemployment, left_on='Start Date', right_on='observation_date', direction='backward')\n",
        "df.drop(columns=['observation_date'], inplace=True)\n",
        "\n",
        "df = pd.merge_asof(df, sp500, left_on='Start Date', right_on='Date', direction='backward')\n",
        "df.drop(columns=['Date'], inplace=True)\n",
        "\n",
        "df = pd.merge_asof(df, sp500_change, left_on='Start Date', right_on='Date', direction='backward')\n",
        "df.drop(columns=['Date'], inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzD2eRk3UdO6",
        "outputId": "dcb847c4-a3f7-415f-9165-35ecdc383a63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-84-b89025b9d328>:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='bfill', inplace=True)  # Backup fill\n"
          ]
        }
      ],
      "source": [
        "# take care of NaNs\n",
        "df.ffill(inplace=True)\n",
        "df.fillna(method='bfill', inplace=True)  # Backup fill\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDWGWSa1UfYa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# drop rows with missing target values\n",
        "df.dropna(subset=['Approving'], inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYzZDWUiUjlJ"
      },
      "outputs": [],
      "source": [
        "# make interaction terms\n",
        "df['Unemployment_Stock'] = df['Unemployment'] * df['SP500_Close']\n",
        "df['GDP_Unemployment'] = df['GDP'] * df['Unemployment']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LKWAd84UufE",
        "outputId": "da0637bf-9ab5-433c-8fc3-93614f6a894b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Start Date', 'End Date', 'Approving', 'Disapproving', 'Unsure/NoData',\n",
            "       'Candidate', 'GDP', 'GDP_Change', 'Change', 'Income_x', 'Income_y',\n",
            "       'Income_Change', 'Unemployment', 'Open_x', 'High_x', 'Low_x',\n",
            "       'SP500_Close', 'Volume_x', 'Dividends_x', 'Stock Splits_x', 'Open_y',\n",
            "       'High_y', 'Low_y', 'Close', 'Volume_y', 'Dividends_y', 'Stock Splits_y',\n",
            "       'SP500_Close_Change', 'Unemployment_Stock', 'GDP_Unemployment'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D82xKRHUk7G"
      },
      "outputs": [],
      "source": [
        "# use GDP, Unemployment, and SP500_Close as predictors (remove Income and GDP_Unemployment)\n",
        "X = df[['GDP', 'Unemployment', 'SP500_Close']]  # focus on the most relevant variables-- but maybe  change??\n",
        "\n",
        "# normalize  predictors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# constant term for intercept\n",
        "X_scaled = sm.add_constant(X_scaled)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srFa7nacU6sk"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "model = sm.OLS(y, X_scaled).fit()\n",
        "print(model.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNuQfkMoU8zu",
        "outputId": "675d42a2-8fd5-49c6-b45e-b3c81e00d202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              Approving   R-squared:                       0.119\n",
            "Model:                            OLS   Adj. R-squared:                  0.117\n",
            "Method:                 Least Squares   F-statistic:                     85.53\n",
            "Date:                Tue, 18 Mar 2025   Prob (F-statistic):           6.51e-52\n",
            "Time:                        22:28:44   Log-Likelihood:                -7404.6\n",
            "No. Observations:                1907   AIC:                         1.482e+04\n",
            "Df Residuals:                    1903   BIC:                         1.484e+04\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         51.5543      0.269    191.393      0.000      51.026      52.083\n",
            "x1            -1.4389      0.561     -2.566      0.010      -2.539      -0.339\n",
            "x2            -0.8797      0.306     -2.873      0.004      -1.480      -0.279\n",
            "x3            -2.9963      0.563     -5.326      0.000      -4.100      -1.893\n",
            "==============================================================================\n",
            "Omnibus:                       16.746   Durbin-Watson:                   0.116\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               25.572\n",
            "Skew:                           0.012   Prob(JB):                     2.80e-06\n",
            "Kurtosis:                       3.567   Cond. No.                         3.95\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33JxDe4vVWjY",
        "outputId": "c0857207-2b4c-4a4c-f4c7-288e9590608b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Performance:\n",
            "MAE: 8.93\n",
            "RMSE: 11.75\n",
            "R-squared: 0.12\n"
          ]
        }
      ],
      "source": [
        "# eval model performance\n",
        "y_pred = model.predict(X_scaled)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-1tXO0BXG8D",
        "outputId": "88bf9b29-dc55-49af-8409-e5cfbb754bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['GDP', 'Unemployment'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMIhWGbRihfWO0ErIGO+IMX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
